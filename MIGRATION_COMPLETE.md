# Architecture Migration Summary

## âœ… Completed Actions

### 1. Dependencies Updated
- **Added**: `cheerio@1.0.0-rc.12` - HTML/XML parsing for HentaiHaven scraper
- **Removed**: `ioredis` - No longer need Redis client

### 2. Files Deleted
- `src/cache/redis.js` - Redis cache implementation (replaced with LRU-only)
- `docker/docker-compose.yml` - Multi-service setup (now single service)

### 3. Directory Restructure
- **Renamed**: `src/providers/` â†’ `src/scrapers/`
  - Reflects new architecture: direct web scraping instead of API calls

### 4. Configuration Files Updated

#### `package.json`
```diff
- "ioredis": "^5.3.2",
+ "cheerio": "^1.0.0-rc.12",
```

#### `.env` & `.env.example`
```diff
- HENTAI_API_URL=...
- HENTAI_API_KEY=...
- REDIS_HOST=...
- REDIS_PORT=...
- REDIS_PASSWORD=...
+ CACHE_MAX_ITEMS=500
+ USER_AGENT=Mozilla/5.0...
+ REQUEST_TIMEOUT=10000
+ MAX_RETRIES=3
```

#### `render.yaml`
- Removed Redis service section
- Removed Redis environment variables
- Simplified to single web service
- Added scraper configuration variables

#### `src/config/env.js`
```diff
- hentaiApi: { url, key }
- redis: { host, port, password, db }
+ scraper: { userAgent, timeout, maxRetries }
+ cache: { maxItems, ttl }
```

### 5. Code Updates

#### `src/cache/index.js`
- Removed Redis logic
- Now uses LRU cache only
- Simplified CacheManager class

#### `src/scrapers/base.js` (formerly providers/base.js)
- Removed external API client configuration
- Added direct HTTP scraping setup
- Updated axios instance with:
  - Scraper-specific headers (User-Agent, Accept, etc.)
  - Retry logic for failed requests
  - Configurable timeout
- Renamed class: `BaseProvider` â†’ `BaseScraper`
- Updated all references: "provider" â†’ "scraper"
- Updated method names: `getProviderFromId()` â†’ `getScraperFromId()`

#### `src/addon/handlers/*.js`
All handler files updated:
- `catalog.js`: Updated imports and variable names
- `meta.js`: Updated imports and variable names  
- `stream.js`: Updated imports and variable names
- Changed: `providers` â†’ `scrapers`
- Changed: `getProvider()` â†’ `getScraper()`
- Changed: `provider.method()` â†’ `scraper.method()`

### 6. New Files Created

#### `src/utils/crypto.js`
ROT13 cipher implementation for HentaiHaven:
- `rot13(str)` - Basic ROT13 substitution
- `decodeMultipleRot13(str, passes)` - Multi-layer decryption
- `extractAndDecode(html, pattern)` - Extract & decode from HTML
- `base64Decode()` / `base64Encode()` - Base64 utilities

#### `ARCHITECTURE_MIGRATION.md`
Complete documentation of migration process and next steps

## ğŸ“Š Architecture Comparison

### Before (Old Architecture)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stremio Addon  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ HTTP
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   hentai-api    â”‚â—„â”€â”€â”€â”€â–ºâ”‚  Redis  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Scraping
         â–¼
   Target Websites
```

**Components**: 3 services (Addon + API + Redis)  
**Cost**: $0-27/month  
**Complexity**: High (multi-repo, network calls)

### After (New Architecture)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Stremio Addon        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Built-in Scrapersâ”‚  â”‚
â”‚  â”‚  - HAnime         â”‚  â”‚
â”‚  â”‚  - HentaiHaven    â”‚  â”‚
â”‚  â”‚  - (HentaiMama)   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚            â”‚ Scraping   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   LRU Cache       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Direct
         â–¼
   Target Websites
```

**Components**: 1 service (Self-contained)  
**Cost**: $0-7/month  
**Complexity**: Low (single repo, direct scraping)

## ğŸ¯ Current State

### âœ… Ready for Use
- [x] LRU cache system
- [x] Configuration management
- [x] Logger utility
- [x] Parser utility
- [x] Quality sorting
- [x] Metadata transformation
- [x] Crypto utility (ROT13)
- [x] Base scraper class
- [x] All handler files
- [x] Deployment configs

### ğŸ”¨ Needs Implementation
- [ ] HAnime scraper logic (port from hentai-api)
- [ ] HentaiHaven scraper logic (port from hentai-api)
- [ ] Update hanime.js with direct scraping
- [ ] Create hentaihaven.js scraper
- [ ] Test scrapers independently
- [ ] Integration testing

## ğŸ“ Next Steps

### Step 1: Clone Reference Repository
```bash
cd ..
git clone https://github.com/shimizudev/hentai-api.git reference-hentai-api
cd hentaistream-addon
```

### Step 2: Study HAnime Scraper
Reference: `reference-hentai-api/src/providers/hanime.ts`
- Understand search API endpoint
- Understand stream manifest fetching
- Understand signature generation
- Note response structure

### Step 3: Port HAnime Scraper
Update `src/scrapers/hanime.js`:
- Remove external API calls
- Add direct scraping logic
- Convert TypeScript to JavaScript
- Add proper error handling

### Step 4: Study HentaiHaven Scraper
Reference: `reference-hentai-api/src/providers/hentai-haven.ts`
- Understand WordPress HTML structure
- Understand iframe extraction
- Understand ROT13 decryption flow
- Note stream URL patterns

### Step 5: Create HentaiHaven Scraper
Create `src/scrapers/hentaihaven.js`:
- Implement HTML parsing with cheerio
- Implement iframe extraction
- Use crypto.js for decryption
- Add proper error handling

### Step 6: Test Scrapers
Test each scraper independently before Stremio integration:
```javascript
// Test HAnime scraper
const HAnimeScraper = require('./src/scrapers/hanime');
const scraper = new HAnimeScraper();

// Test search
const results = await scraper.search('overflow', 10);
console.log(results);

// Test metadata
const meta = await scraper.getMeta('hanime-overflow');
console.log(meta);

// Test streams
const streams = await scraper.getStreams('hanime-overflow:1:1');
console.log(streams);
```

## âš ï¸ Important Notes

1. **No External Dependencies**: The addon now runs completely standalone
2. **Direct Scraping**: All scrapers make direct HTTP requests to target sites
3. **Rate Limiting**: Implement request delays to avoid IP bans
4. **Error Handling**: Scrapers must handle network failures gracefully
5. **Cache Aggressively**: Reduce load on target sites
6. **User-Agent Rotation**: Consider rotating User-Agents if blocked

## ğŸš€ Testing Checklist

Once scrapers are implemented:

- [ ] Test HAnime search
- [ ] Test HAnime metadata
- [ ] Test HAnime streams
- [ ] Test HentaiHaven search
- [ ] Test HentaiHaven metadata
- [ ] Test HentaiHaven streams
- [ ] Test cache hit/miss
- [ ] Test error scenarios
- [ ] Test in Stremio client
- [ ] Deploy to Render
- [ ] Production smoke test

## ğŸ“š Reference Documentation

- **PROJECT_PLAN.md**: Complete roadmap with all phases
- **ARCHITECTURE_MIGRATION.md**: Detailed migration steps and reference
- **SETUP.md**: Setup instructions (needs update for new arch)
- **IMPLEMENTATION.md**: Implementation status (needs update)
- **README.md**: Project overview (needs update)

---

**Status**: Architecture migration complete, ready for Phase 1 scraper implementation!
